library(devtools)
dm(x)
library(Test)
library(Test)
library(test)
library(Ttest)
library(Test)
data <- c(12, 12)
results <- dm(data)
results
devtools::load_all(".")
## End: 20191009
## Gaussian Process linear regression model
# https://topepo.github.io/caret/train-models-by-tag.html#gaussian-process
# http://www.rebeccabarter.com/blog/2017-11-17-caret_tutorial/
library(require(rgdal))
setwd("Z:\\Projects\\PastureSmarts\\Senani_working\\24_Data_Processing\\Ellinbank")
path <- setwd("Z:\\Projects\\PastureSmarts\\Senani_working\\24_Data_Processing\\Ellinbank")
dir()
## Get a list with files
file.names <- list.files(path, pattern="*.csv", full.names=T, recursive=FALSE)
## Date	Pdk	kg_DM_ha	U_ID	ORIG_FID
df_f <- data.frame()
for (f in file.names){
shp1 <- read.csv(f)
print("success!")
df <- data.frame(shp1)
df_f <- rbind(df_f,df)
}
head(df_f)
tail(df_f)
dim(df_f)
### Only complete cases
df_f_complete <- df_f[complete.cases(df_f), ]
dim(df_f_complete)
head(df_f_complete)
names(df_f_complete)
##write.csv(df_f, "Combined_data_20191008.csv")
## Delete the variables that had the same values
#
names(df_f_complete)
summary(df_f_complete)
df_f_complete$X <- NULL
df_f_complete$Paddock_Na <- NULL
df_f_complete$Pixel_Numb <- NULL
df_f_complete$CalCut_Ht <- NULL
df_f_complete$OBJECTID <- NULL
df_f_complete$Date_ <- NULL
df_f_complete$PRM_Start <- NULL
df_f_complete$RPM_End <- NULL
df_f_complete$Bare__PC <- NULL
df_f_complete$Live_PC <- NULL
df_f_complete$Dead_PC <- NULL
df_f_complete$Botanal1 <- NULL
df_f_complete$Botanal2 <- NULL
df_f_complete$Botanal3 <- NULL
df_f_complete$Ruler_Ht1 <- NULL
df_f_complete$Ruler_Ht2 <- NULL
df_f_complete$Ruler_Ht3 <- NULL
df_f_complete$PRG_Leaf <- NULL
df_f_complete$CalCut_FRE <- NULL
df_f_complete$GlobalID <- NULL
df_f_complete$Shape__Are <- NULL
df_f_complete$Shape__Len <- NULL
df_f_complete$n <- NULL
df_f_complete$Mean_ID <- NULL
df_f_complete$Median_ID <- NULL
write.csv(df_f_complete, 'UAV_Python_Test_20191113.csv')
## Nice correlaiton plot
res <- cor(df_f_complete)
round(res, 2)
library(corrplot)
corrplot(res, type = "upper", order = "hclust",
tl.col = "black", tl.srt = 45)
#### Modelling########################
### With Full dataset
library(caret)
data_full <- as.data.frame(df_f_complete)
names(data_full)
## See all good
library(Boruta)
set.seed(1981)
boruta.train_full <- Boruta(CalCut_DRY ~., data = data_full, doTrace = 2)
print(boruta.train_full)
plot(boruta.train_full)
plot(boruta.train_full, cex.axis = 0.8, las=1)
boruta.train_full$finalDecision
write.csv(boruta.train_full$finalDecision, 'Senan_test_20191011.csv')
dim(data_full)
## RF model
set.seed(1981)
rf_model_full <- ranger(CalCut_DRY ~., data = data_full, importance = "permutation")
chari_p <- predict(rf_model_full, data_full)
plot(data_full$CalCut_DRY, chari_p$predictions)
cor(data_full$CalCut_DRY, chari_p$predictions)
abline(0,1)
## Simple VIP
rf_model_full_vi <- rf_model_full$variable.importance
#barplot(rf_model_full_vi, horiz = TRUE, las = 1)
## Fancy VIP
var_importance <- data.frame(variable=setdiff(colnames(data_full), "CalCut_DRY"),
importance=as.vector(rf_model_full_vi))
library(dplyr)
var_importance <- arrange(var_importance, desc(importance))
var_importance$variable <- factor(var_importance$variable, levels=var_importance$variable)
library(ggplot2)
p <- ggplot(var_importance, aes(x=variable, weight=importance, fill=variable))
p <- p + geom_bar() + ggtitle("Variable Importan")
p <- p + xlab("Sentinel 2 Bands and derived VIs") + ylab("Variable Importance")
p <- p + scale_fill_discrete(name="Variable Name")
p + theme(axis.text.x=element_blank(),
axis.text.y=element_text(size=12),
axis.title=element_text(size=16),
plot.title=element_text(size=18),
legend.title=element_text(size=16),
legend.text=element_text(size=12))
## 10 fold cross validaiton
library(caret)
fit_control <- trainControl(method = "cv", number = 10)
rf_fit <- train(CalCut_DRY ~ ., data = data_full, method = "ranger", trControl = fit_control)
rf_fit
###################################################################################################
############################################### Run radom forest mean with mean DM  ###############
###################################################################################################
head(data_full)
library(dplyr)
DM_mean <- data_full %>%
dplyr::group_by(Date, U_ID) %>%
dplyr::summarise(
n = n(),
DM_mean=mean(DM, na.rm = TRUE)
)
head(DM_mean)
dim(DM_mean)
DM_mean_f <- as.data.frame(DM_mean)
head(DM_mean_f)
## Remove duplicate records
names(data_full)
data_full_f <- data_full[,-21]
head(data_full_f)
dim(data_full_f)
data_no_dup  <- dplyr::distinct(data_full_f)
head(data_no_dup)
dim(data_no_dup)
final_df_m  <- dplyr::inner_join(DM_mean, data_no_dup, by = c('Date', 'U_ID'))
dim(final_df_m)
head(final_df_m)
final_df_m <- as.data.frame(final_df_m)
names(final_df_m)
#final_df_m$b11 <- NULL
#final_df_m$b12 <- NULL
## See all good
library(Boruta)
names(final_df_m[,4:22])
set.seed(1981)
#? Boruta
#### Change the Square bracket whetaher we keep B11 and B12 in the model
boruta.train_dup <- Boruta(DM_mean ~., data = final_df_m[,4:22], doTrace = 2, maxRuns = 1000)
print(boruta.train_dup)
plot(boruta.train_dup)
boruta.train_dup$finalDecision
plot(boruta.train_dup, cex.axis = 0.8, las=1)
## RF model
final_dup_data <- final_df_m[,4:22]
names(final_dup_data)
## drop B16
#final_dup_data$b11 <- NULL
#final_dup_data$b12 <- NULL
set.seed(1984)
rf_model_dup <- ranger(DM_mean ~., data = final_dup_data, num.trees = 1000, mtry = 6, importance = "permutation", min.node.size = 5)
print(rf_model_dup)
data <- c(1,2)
dm(data)
devtools::load_all("E:/Package/Test")
devtools::load_all("E:/Package/Test")
devtools::load_all("E:/Package/Test")
data <- c(1,2)
dm(data)
devtools::load_all("E:/Package/Test")
data <- c(1,2)
data <- c(1,2)
dm(data)
devtools::load_all("E:/Package/Test")
data <- c(1,2)
dm(data)
devtools::load_all("E:/Package/Test")
devtools::load_all("E:/Package/Test")
? dm
?dm
??dm
?? Test::dm
? Test::dm
devtools::load_all("E:/Package/Test")
? Test::dm
? Test::dm
library(Test)
